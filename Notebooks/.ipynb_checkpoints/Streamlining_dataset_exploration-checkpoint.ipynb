{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ae8977",
   "metadata": {},
   "source": [
    "# Streamlining the Process of Exploring Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d72ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71b4ab",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59dbf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can run this if working in the same folder as the data\n",
    "def read_data(survey_section, discipline, dataset):\n",
    "    ''' Loads UCUES datasets present in the Data Mural Project GitHub Data Folder and returns the dataset as a pandas\n",
    "    dataframe\n",
    "    \n",
    "    Params:\n",
    "        survey_section  str, Shortened section name, ex: Satis \n",
    "        discipline    str, Shortened discipline name, ex: Hum\n",
    "        dataset    int, the sub-dataset from the specified survey section \n",
    "    '''\n",
    "    #Creates the path for where the file is located in the local environment\n",
    "    file_path = \"{}_data_{}_{}.csv\".format(survey_section, discipline, dataset)\n",
    "    DF = pd.read_csv(file_path, encoding='utf-16le', sep = '\\t')\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d125b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_file_path(file_path, UCUES_dataset, survey_section, discipline, dataset):\n",
    "    ''' Loads UCUES datasets present in the Data Mural Project GitHub Data Folder and returns the dataset as a pandas\n",
    "    dataframe\n",
    "    \n",
    "    Params:\n",
    "        file_path     str, file_path to the dataset on your local environment, ex: /Users/omarramos/Documents/Data_Mural_Project/Data\n",
    "        UCUES_dataset   str, name of the UCUES survey section and sub-dataset number, ex: Satisfaction-1\n",
    "        survey_section  str, Shortened section name, ex: Satis \n",
    "        discipline    str, Shortened discipline name, ex: Hum\n",
    "        dataset    int, the sub-dataset from the specified survey section \n",
    "    '''\n",
    "    #Creates the path for where the file is located in the local environment\n",
    "    file_path = \"{}/Data/UCUES-{}/{}_data_{}_{}.csv\".format(file_path, UCUES_dataset,survey_section, discipline, dataset)\n",
    "    DF = pd.read_csv(file_path, encoding='utf-16le', sep = '\\t')\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2cd8a",
   "metadata": {},
   "source": [
    "## Open and merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fa5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for how to use the function to open datasets for different disciplines for the same section\n",
    "# and for how to create a new dataframe with all the disciplines and their scores merged together\n",
    "\n",
    "def create_dataset(file_path, UCUES_dataset, survey_section, discipline, dataset):\n",
    "    disciplines = [\"Arts\", \"Hum\", \"Life\", \"Eng\", \"Health\", \"Phys\", \"Prof\", \"Social\", \"Undec\"]\n",
    "    dataset = dataset\n",
    "    survey_section = survey_section\n",
    "    file_path = file_path\n",
    "    UCUES_dataset = UCUES_dataset\n",
    "    \n",
    "    #make array with the different datasets for each discipline\n",
    "    array_dfs = []\n",
    "    for discipline in disciplines:\n",
    "        df = read_data_from_file_path(file_path, UCUES_dataset, survey_section, discipline, dataset)\n",
    "        df[discipline] = [discipline for i in range(len(df))]\n",
    "        array_dfs.append(df)\n",
    "        \n",
    "    #merge datasets for each discipline\n",
    "    concat_df = pd.concat(array_dfs)\n",
    "    \n",
    "    #one-hot encode discipline columns\n",
    "    concat_df = concat_df.fillna(0) #convert NaNs to 0\n",
    "    for discipline in disciplines:\n",
    "        concat_df.loc[concat_df[discipline] == discipline, discipline] = 1\n",
    "        \n",
    "    # Get one hot encoding of column with scores\n",
    "    one_hot = pd.get_dummies(concat_df['Pivot Field Values'])\n",
    "    # Drop column with scores as it is now encoded\n",
    "    one_hot_df = concat_df.drop('Pivot Field Values',axis = 1)\n",
    "    # Join the encoded df\n",
    "    one_hot_df = one_hot_df.join(one_hot)\n",
    "    \n",
    "    #rename columns\n",
    "    one_hot_df = one_hot_df.rename(columns = {\"Label1\": \"Statement\", \"Calculation1\": \"Percent_pop\", \n",
    "                                              \"Total\": \"Pop_raw_count\"})\n",
    "    \n",
    "    #drop duplicate rows\n",
    "    new_df = one_hot_df.drop_duplicates()\n",
    "    #reset index\n",
    "    new_df = new_df.reset_index()\n",
    "    \n",
    "    #convert string percent column to actual percentages\n",
    "    for x in range(len(new_df[\"Percent_pop\"])):\n",
    "        new_df[\"Percent_pop\"][x] = float(new_df[\"Percent_pop\"][x].replace(\"%\", \"\"))/100\n",
    "    \n",
    "    return new_df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
